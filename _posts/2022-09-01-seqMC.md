---
title: 'Sequential Monte Carlo: Introduction and advances'
date: 22022-09-01
permalink: /posts/2018/01/seqMC/
tags:
  - Sequential Monte Carlo
  - Feynmac-Kac
  - Particle filtering
---

This note is an attempt to convey the main ideas and notions of the talk entitled "Sequential Monte Carlo: Introduction and advances" given by Nicolas Chopin (ENSAE, Paris, France) during the Stochastic algorithm Day 2017 (*Journée algorithmes stochastiques 2017*). This conference was held at Université Paris Dauphine (Paris, France) on December 1st, 2017. 


## Feynmac-Kac models

A Feynman-Kac model is made of :

* a Markov chain in $$\mathcal{X}$$ with
  * Initial law : $$dx_0\in\mathcal{X}\mapsto m_0(dx_0)$$
  * Markov kernel (at iteration $$t$$) : $$dx_t \in\mathcal{X} \mapsto m_t(x_{t-1},dx_t)=\pi(x_t\vert x_{t-1})$$

* a sequence of potential functions $$G_0 : \mathcal{X} \rightarrow \mathbb{R}^+$$, $$G_t : \mathcal{X}\times \mathcal{X} \rightarrow \mathbb{R}^+$$

The aim is to compute sequentially quantities of the form :

$$\begin{aligned}\mathbb{Q}_t(\phi)=\frac{1}{Z_t}\mathbb{E}\left[ \phi(X_t)G_0(X_0)\prod\limits_{s=1}^tG_s(X_{s-1},X_s)\right]\end{aligned}$$

where

$$\begin{aligned}
Z_t=\mathbb{E}\left[G_0(X_0)\prod\limits_{s=1}^tG_s(X_{s-1},X_s)\right].
\end{aligned}$$

**Example:**
If $$G_t(x_{t-1},x_t):=\boldsymbol{1}_{A_t}(x_t)$$, then
$$Z_t = \mathbb{P}(\forall s\le t, \; X_s\in A_s)$$ and
$$\mathbb{Q}_t = \pi(X_t \vert X_s\in A_s : s \le t)$$ Notice in
particular that 

$$\begin{aligned}
Z_t=\int \underbrace{\left(\int G_0(x_0)\prod\limits_{s=1}^tG_s(x_{s-1},x_s)\pi(x_0,...,x_t)dx_0...dx_{t-1}\right)}_{:=p_t(x_t)}dx_t
\end{aligned}$$

$$\begin{aligned}
\mathbb{Q}_t(\phi)&= \frac{1}{Z_t}\int \phi(x_t)\left(\int G_0(x_0)\prod\limits_{s=1}^tG_s(x_{s-1},x_s)\pi(x_0,...,x_t)dx_0...dx_{t-1}\right)dx_t\\
&= \frac{1}{Z_t}\int \phi(x_t)p_t(x_t)dx_t=\int \phi(x_t)\underbrace{\frac{p_t(x_t)}{\int p_t(x_t)dx_t}}_{:=\mathbb{Q}_t(x_t)}dx_t=\int \phi(x_t)\mathbb{Q}_t(x_t)dx_t
\end{aligned}$$

Then $$\mathbb{Q}_t(x_t)$$ can be seen as a probability density and
$$\mathbb{Q}_t(\phi)$$ as the expectation of $$\phi(X_t)$$ when
$$X_t \sim \mathbb{Q}_t(x_t)$$.



**Example:**
Hidden Markov models

Imagine that the Markov chain $$(X_t)$$ is observed through

$$\begin{aligned}
Y_t=h(X_t)+\text{ noise }
\end{aligned}$$

and take $$G_t(x_{t-1},x_t)=\pi(y_t\vert x_t)$$ the density of $$Y_t$$ conditional on $$X_t=x_t$$. Then,

$$\begin{aligned}
p_t(x_t)&=\int \prod_{s=0}^t \pi(y_s\vert x_s\pi(x_0,...,x_t)dx_0...dx_{t-1}\\
&=\int\pi(y_0,...,y_t,x_0,...,x_t)dx_0...dx_{t-1}=\pi(y_0,...,y_t,x_t)
\end{aligned}$$

And therefore 

$$\begin{aligned}
Z_t=\int \pi(y_0,...,y_t,x_t)dx_t=\pi(y_0,...,y_t)
\end{aligned}$$

is the likelihood of the observations and

$$\begin{aligned}
\mathbb{Q}_t(x_t)=\pi(y_0,...,y_t,x_t)/\pi(y_0,...,y_t)=\pi(x_t\vert y_0,...,y_t)
\end{aligned}$$

is the law of $$X_t$$ conditional on the observations.

## Particle Filtering

Particle filtering is used to approximate the probability measure
$$\mathbb{Q}_t$$ sequentially

-   Initialization : $$t=0$$

    -   Generate $$N$$ samples from $$m_0(dx_0)$$ :
        $$X_0^{(i)} \sim m_0(dx_0) : i\in[\![1,N]\!]$$

    -   Compute initial weights :
        $$W_0^{(i)} =G_0(X_0^{(i)} )/\sum\limits_{j=1}^N G_0(X_0^{(j)} ) : i\in[\![1,N]\!]$$

-   For time $$t>0$$ :

    -   Do for $$i\in [\![1,N]\!]$$ :

        -   Draw an index $$A_{t-1}^{i}$$ from $$[\![1,N]\!]$$ with
            probabilities
            $$\mathbb{P}\left(A_{t-1}^{i}=k\right)\propto W_{t-1}^{(k)}$$

        -   Generate
            $$X_t^{(i)} \sim m_t\left(X_{t-1}^{\left(A_{t-1}^{i}\right)}, dx_t\right)$$

    -   Compute the new weights :
        $$W_t^{(i)} =G_t(X_{t-1}^{\left(A_{t-1}^{i}\right)},X_t^{(i)} )/\sum\limits_{j=1}^N G_t(X_{t-1}^{\left(A_{t-1}^{j}\right)},X_t^{(j)} )$$

The quantities of interest are computed using

$$\begin{aligned}
\mathbb{Q}_t^N(\phi)=\sum\limits_{i=1}^N W_t^{(i)}\phi(X_t^{(i)}) \approx \mathbb{Q}_t(\phi)
\end{aligned}$$

and

$$\begin{aligned}
Z_t^N=\prod\limits_{s=0}^t\left[\frac{1}{N}\sum\limits_{i=1}^N G_t(X_{t-1}^{\left(A_{t-1}^{i}\right)},X_t^{(i)} ) \right]\approx Z_t
\end{aligned}$$


<figure>
  <img src="/images/seqMC/part_schema.png"/>
  <figcaption>Particle filtering in a sketch.</figcaption>
</figure>


In this particle filter formulation, the particles are generated using
the kernel $$m_t(x_{t-1},dx_t)$$. In practice, this generating kernel
doesn't have to match the kernel $$f_t(x_{t-1},dx_t)$$ of the Markov chain
of interest, but when it is the case, the corresponding PF is called a
bootstrap filter.

In particular, in the Hidden Markov models, if $$f_t$$ is the Markov
kernel of the underlying process $$(X_t)$$ then, for any kernel $$m_t$$, if
the potential functions are of the form

$$\begin{aligned}
G_0(x_0)=\frac{f_0(x_0)\pi(y_0\vert x_0)}{m_0(x_0)} \;,  \quad G_t(x_{t-1},x_t)=\frac{f_t(x_{t-1},dx_t)\pi(y_t\vert x_t)}{m_t(x_{t-1},dx_t)}
\end{aligned}$$

 then $$\mathbb{Q}_t$$ will still match the filtering
distribution, i.e. the law of $$X_t$$ conditional to the data.


*Proof.* For a Markov chain $$(X_t)$$ with kernel $$f_t$$ :

$$\begin{aligned}
\pi(x_0,...,x_t)=\pi(x_0)\prod\limits_{s=1}^t\pi(x_s\vert x_{s-1})=f_0(x_0)\prod\limits_{s=1}^t f_s(x_{s-1},dx_s)
\end{aligned}$$

Then, the Feynman-Kac model with Markov chain $$(\tilde X_t)$$ with kernel
$$m_t$$ and potential functions $$G_t$$ defined above
verifies 

$$\begin{aligned}
\tilde p_t(\tilde X_t=\tilde x_t)&=\int \frac{f_0(\tilde x_0)\pi(y_0 \vert \tilde x_0)}{m_0(\tilde x_0)}\prod_{s=1}^t \frac{f_s(\tilde x_{s-1},d\tilde x_s)\pi(y_s\vert \tilde x_s)}{m_s(\tilde x_{s-1},d\tilde x_s)}\pi(\tilde x_0,...,\tilde x_t)d\tilde x_0...d\tilde x_{t-1}\\
&= \int f_0(\tilde x_0)\pi(y_0 \vert \tilde x_0)\prod_{s=1}^t f_s(\tilde x_{s-1},d\tilde x_s)\pi(y_s\vert \tilde x_s)d\tilde x_0...d\tilde x_{t-1}\\
&= \int \pi(x_0,...,x_t)\prod_{s=0}^t \pi(y_s\vert x_s)dx_0...d x_{t-1} \\
&= \int \pi(x_0,...,x_t) \pi(y_0,...,y_t\vert x_0,..., x_t)dx_0...d x_{t-1}\\
&=\int\pi(y_0,...,y_t,x_0,...,x_t)dx_0...dx_{t-1} \\
&=\pi(y_0,...,y_t,x_t)=p_t(X_t=x_t)
\end{aligned}$$

Therefore the probability $$\tilde{\mathbb{Q}}_t$$ associated with the
chain $$(\tilde X_t)$$ is exactly the filtering distribution of the
underlying process $$(X_t)$$. ◻


The generating kernel $$m_t$$ is chosen to minimize the variance of $$G_t$$: the optimal choice is then the distribution of $$X_t$$ conditional to
$$X_{t-1}$$ and $$Y_t$$ (intractable in general...).

## Resampling

Resampling is the process that takes as an input a weighted sample
$$\lbrace (X^{(i)},W^{(i)})\rbrace_{i\in[\![1,N]\!]}$$ and returns
resampled variables $$\lbrace X^{(A^i)} \rbrace_{i\in[\![1,N]\!]}$$ where
$$A^i$$ is a random index in $$[\![1,N]\!]$$. A good resampling scheme
guarantees

$$\begin{aligned}
\frac{1}{N}\sum\limits_{i=1}^N\delta(X^{(A^i)})\approx \sum\limits_{i=1}^N W^n\delta(X^{(i)})
\label{GS}
\end{aligned}$$ 

i.e. the empirical probability measure of the resampled
variables is close to the weighted empirical measure of the input
variables.

Denote
$$F_N : x\in\mathbb{R}_+ \mapsto \sum\limits_{i=1}^N W^{(i)}\boldsymbol{1}(x\ge i)\in[0,1]$$
the cumulative distribution function associated with the normalized
weights $$(W^{(i)})$$. Three common resampling schemes are described
below.


### Multinomial resampling

-   For $$i\in [\![1,N]\!]$$ :

    -   Draw $$U^{(i)}\sim \mathcal{U}(0,1)$$

    -   Return $$A^i=F^{-1}_N(U^{i})$$

### Stratified resampling

-   For $$i\in [\![1,N]\!]$$ :

    -   Draw $$U^{(i)}\sim \mathcal{U}(0,1)$$

    -   Return $$A^i=F^{-1}_N(\frac{i-1+U^{i}}{N} )$$

### Systematic resampling

-   Draw $$U\sim \mathcal{U}(0,1)$$

-   For $$i\in [\![1,N]\!]$$ :

    -   Return $$A^i=F^{-1}_N(\frac{i-1+U}{N} )$$

<figure>
  <img
  src="/images/seqMC/inv_cdf.png" >
  <figcaption>Example of inverse cumulative distribution $F_N$, $N=4$.
$\lbrace U^{(k)}, 1\le k\le 3\rbrace$ are samples drawn using
multinomial resampling.</figcaption>
</figure>

Stratified and systematic resampling are used in practice because they
are a bit faster and lead to lower variance estimates numerically. But
for theory, multinomial resampling is preferred as it is easier to study
and constitutes a good sampler in the sense described at the beginning of this section. Hence, little
theoretical background is provided for stratified and systematic
sampling, regarding for instance their consistency.

## Consistency results

A resampling scheme is consistent if it preserves weak convergence. A
theorem states that an unbiased resampling scheme is consistent if the
collection of variables

$$\begin{aligned}
\left\lbrace \#^i:=\sum\limits_{j=1}^N\boldsymbol{1}(A^j=i)=\text{Card}\lbrace j\in[\![1,N]\!] : A^j=i\rbrace \right\rbrace_{i\in[\![1,N]\!]}
\end{aligned}$$

is negatively associated, i.e., for every pair of disjoint subsets
$$I_1,I_2 \subset [\![1,N]\!]$$,

$$\begin{aligned}\text{Cov}\left(\varphi_1(\lbrace \#^i : i\in I_1\rbrace), \varphi_2(\lbrace \#^i : i\in I_2\rbrace)\right)\le 0
\end{aligned}$$

for all non-decreasing functions
$$\varphi_k : \mathbb{R}^{|I_k|}\rightarrow \mathbb{R}$$,
$$k\in\lbrace 1,2\rbrace$$, such that the covariance is well-defined.\
This theorem is used to demonstrate that multinomial and residual
resampling are consistent (which was a known fact) but also stratified
and SSP resampling (which is a new fact). However, the theorem can't be
applied to systematic resampling.

## References

* Nicolas Chopin (2017, December). *Sequential Monte Carlo: introduction,
recent advances*. Paper presented at \"Journée algorithmes
stochastiques\", Université Paris Dauphine, Paris, France

