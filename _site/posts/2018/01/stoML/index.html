

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Stochastic algorithms in Machine Learning - Mike Pereira</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Mike Pereira">
<meta property="og:title" content="Stochastic algorithms in Machine Learning">


  <link rel="canonical" href="http://localhost:4000/posts/2018/01/stoML/">
  <meta property="og:url" content="http://localhost:4000/posts/2018/01/stoML/">



  <meta property="og:description" content="This note is an attempt to convey the main ideas and notions of the talk entitled “Stochastic algorithms in Machine Learning” given by Aymeric Dieuleveut (EPFL, Lausanne, Switzerland) during the Stochastic algorithm Day 2017 (Journée algorithmes stochastiques 2017). This conference was held at Université Paris Dauphine (Paris, France) on December 1st, 2017.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2018-01-18T00:00:00-08:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Mike Pereira",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Mike Pereira Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Mike Pereira</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/talks/">Talks</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/mike.png" class="author__avatar" alt="Mike Pereira">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Mike Pereira</h3>
    <p class="author__bio">Assistant professor (Enseignant-chercheur, Tenure track), Mines Paris - PSL</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Fontainebleau, France</li>
      
      
      
      
        <li><a href="mailto:mike.pereira@minesparis.psl.eu"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
        <li><a href="https://www.researchgate.net/profile/Mike-Pereira"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a></li>
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/mike-pereira"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=96uBOBMAAAAJ&hl=en&oi=ao"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
        <li><a href="https://orcid.org/0000-0002-7899-2690"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Stochastic algorithms in Machine Learning">
    <meta itemprop="description" content="This note is an attempt to convey the main ideas and notions of the talk entitled “Stochastic algorithms in Machine Learning” given by Aymeric Dieuleveut (EPFL, Lausanne, Switzerland) during the Stochastic algorithm Day 2017 (Journée algorithmes stochastiques 2017). This conference was held at Université Paris Dauphine (Paris, France) on December 1st, 2017.">
    <meta itemprop="datePublished" content="January 18, 2018">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Stochastic algorithms in Machine Learning
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  11 minute read
	
</p>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-01-18T00:00:00-08:00">January 18, 2018</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p>This note is an attempt to convey the main ideas and notions of the talk entitled “Stochastic algorithms in Machine Learning” given by Aymeric Dieuleveut (EPFL, Lausanne, Switzerland) during the Stochastic algorithm Day 2017 (<em>Journée algorithmes stochastiques 2017</em>). This conference was held at Université Paris Dauphine (Paris, France) on December 1st, 2017.</p>

<h2 id="introduction">Introduction</h2>

<p>The goal of supervised Machine Learning algorithms is to predict the
values of some unknown variable from known explanatory variables, given
a set of observations. Contrary to purely statistical algorithms, no
model has to be specified to the algorithm. In many applications, both
the number of observations \(n\) and the number of explanatory variables
\(d\) can be large. Stochastic algorithms are used in such large scale
frameworks to make prediction tractable.</p>

<h2 id="supervised-machine-learning">Supervised Machine Learning</h2>

<p>Consider an input/output pair \((X,Y)\in\mathcal{X}\times\mathcal{Y}\),
\(\mathcal{Y}\subset \mathbb{R}\), with unknown joint distribution
\(\rho\).
The goal is to find a function
\(\theta : \mathcal{X} \rightarrow \mathbb{R}\) such that \(\theta(X)\) is a
good prediction for \(Y\). To do so, we consider a loss function
\(l : \mathcal{Y}\times \mathbb{R} \rightarrow \mathbb{R}_+\) such that
\(l(y,\theta(x))\) is the loss from predicting \(y\) using \(\theta(x)\).</p>

<p>The Generalization risk (or true risk) is defined as</p>

\[\begin{aligned}
\mathcal{R}(\theta):=\mathbb{E}_\rho[l(Y, \theta(X))]
\end{aligned}\]

<p>and is a measure of the quality of \(\theta(X)\) as a predictor of \(Y\). Given that \(\rho\)
is unknown, we can’t in general compute directly this risk.</p>

<p>Starting from a set of \(n\) observations
\((x_i,y_i)\in\mathcal{X}\times \mathcal{Y}\), \(i\in[\![1,n]\!]\) assumed
to be i.i.d. with (unknown) distribution \(\rho\), the Empirical risk (or
training error) is defined as</p>

\[\begin{aligned}
\widehat{\mathcal{R}}(\theta)=\frac{1}{n}\sum\limits_{i=1}^nl(y_i,\theta(x_i))
\end{aligned}\]

<p>and is used in practice to choose the best predictor \(\theta\),
considering the observations and some regularisation factor
\(\Omega(\theta)\), through the Empirical Risk Minimisation (ERM) problem
:</p>

\[\begin{aligned}
\theta^* = \min\limits_\theta \left[\widehat{\mathcal{R}}(\theta) + \mu\Omega(\theta)\right]=\min\limits_\theta \left[\frac{1}{n}\sum\limits_{i=1}^nl(y_i,\theta(x_i)) + \mu\Omega(\theta)\right]
\end{aligned}\]

<p>From now on, linear functions are considered. We reparametrize :</p>

\[\begin{aligned}
\theta(X) = \langle \theta, \Phi(X) \rangle, \quad \theta\in\mathbb{R}^d,\quad \Phi : \mathcal{X}\rightarrow \mathbb{R}^d
\end{aligned}\]

<p>The high number of explanatory variables \(d\) pushes us to choose first
order algorithm for the ERM, namely the Gradient Descent algorithm. For
instance, choosing second order algorithms such as the Newton-Raphson
algorithm, would imply to compute a \(d\times d\) matrix at each
iteration: the Hessian of the overall loss.</p>

<p><img src="/images/stoML/alg1.png" alt="" /></p>

<p>Each iteration implies \(\mathcal{O}(dn)\) operations for the computation
of the Gradient. Stochastic algorithms are used to reduce this number.
In particular, the Stochastic Gradient algorithm only implies
\(\mathcal{O}(d)\) operations per iteration.</p>

<h2 id="stochastic-gradient-descent">Stochastic Gradient descent</h2>

<p>The idea of Stochastic Gradient Descent (SGD) is to replace, at each
iteration \(k\), the gradient of the empirical risk
\(\nabla\widehat{\mathcal{R}}(\theta^{(k-1)})\) by a gradient function
\(g^{(k)}(\theta^{(k-1)})\) cheaper to compute and verifying :</p>

\[\begin{equation}
\mathbb{E}[g^{(k)}(\theta^{(k-1)})\vert \mathcal{F}_{k-1} ]=\nabla\widehat{\mathcal{R}}(\theta^{(k-1)})
\tag{1}\label{SGD_origin}
\end{equation}\]

<p>for a filtration \((\mathcal{F}_{k})_{k\ge 0}\) such
that \(\theta^{(k)}\) is \(\mathcal{F}_k\)-measurable.</p>

<p>Notice that the empirical risk can be written :</p>

\[\begin{aligned}
\widehat{\mathcal{R}}(\theta)=\frac{1}{n}\sum\limits_{i=1}^nf_i(\theta), \quad f_i : \theta \mapsto l(y_i,\theta(x_i))
\end{aligned}\]

<p>Consider the filtration
\(\mathcal{F}_k=\sigma\left((x_i,y_i)_{1\le i \le n}, (i_j)_{0\le j \le k}\right)\)
where \((i_j)_{j \ge 0}\) are independent indices uniformly sampled from
\([\![1,n]\!]\). It can be shown that \(g^{(k)}:=\nabla{f_{i_k}}\) verifies \eqref{SGD_origin}. The SGD algorithm is then described below.</p>

<p><img src="/images/stoML/alg2.png" alt="" /></p>

<p>To reduce noise effect due to the proxy used for the gradient
computation step, we may take the average of all states \(\theta^{(k)}\)
as an estimator of the optimum, instead of just last one. This average
\(\bar\theta^{(k)}\) may be computed "on line", meaning that it can be
updated at each iteration without requiring the storage of all previous
states.</p>

<p><img src="/images/stoML/alg3.png" alt="" /></p>

<p>Assume the following properties for the loss function \(l\) :</p>

<ul>
  <li>
    <p>\(l\) is \(L\)-smooth, i.e. \(L\) is a lower bound of the eigenvalues of
the Hessian matrix of \(l\) at any point</p>
  </li>
  <li>
    <p>\(l\) is \(\mu\)-strongly convex, i.e. \(\mu\) is a upper bound of the
eigenvalues of the Hessian matrix of \(l\) at any point</p>
  </li>
</ul>

<p>In particular, at any points of evaluation \((u,v)\), \(l\) verifies :</p>

\[\begin{aligned}
\langle \nabla l(v), u-v\rangle + \mu\Vert u-v\Vert^2 \le l(u)-l(v) \le \langle \nabla l(v), u-v\rangle + L\Vert u-v\Vert^2
\end{aligned}\]

<p>With some additional assumptions on the observations \(\Phi(x_i)\)
(bounded variance and invertible experimental covariance matrix), it can
be shown that then empirical risk also verifies those two properties.\</p>

<h3 id="importance-of-the-learning-rate-gamma_k">Importance of the learning rate \(\gamma_k\)</h3>

<p>For smooth and convex problems, it was shown that almost surely,
\(\theta_k \rightarrow \theta^*\) if</p>

\[\begin{aligned}
\sum\limits_{k=1}^\infty \gamma_k =\infty \quad \sum\limits_{k=1}^\infty \gamma_k^2 =\infty
\end{aligned}\]

<p>and asymptotically, for
\(\gamma_k =\frac{\gamma_0}{k}, \gamma_0 \ge \frac{1}{\mu}\),
\(\sqrt{k}(\theta_k - \theta^*) \mathop{\rightarrow}\limits^d \mathcal{N}(0,V)\).</p>

<h3 id="comparison-of-convergence-rate">Comparison of convergence rate</h3>

<p>The convergence rate of an optimization algorithm measures the speed of
convergence of torwards the solution of the problem. It is, with our
notations, given by the speed at which
\((\widehat{\mathcal{R}}(\theta^{(k)}))_{k\ge 0}\) converges to the
minimum of \(\widehat{\mathcal{R}}\). Let’s compare the convergence rate
of GD and (A)SGD for both convex and strongly convex functions.</p>

<p><img src="/images/stoML/table.png" alt="" /></p>

<p>One one hand, GD can converge much master to the optimum \(\theta^*\) than
SGD. But on the other hand, each iteration of GD is more costly (by a
factor \(n\)) than an iteration of SGD. The idea is to come up with a way
to get the best of both worlds.</p>

<h2 id="stochastic-average-gradient">Stochastic Average Gradient</h2>

<p>The Stochastic Average Gradient algorithm, is a SGD algorithm in which
the at each iteration, the full gradient \(g^{(k)}\) given by</p>

\[\begin{aligned}
g^{(k)}=\frac{1}{n}\sum\limits_{i=1}^n\nabla f_i(\theta^{(k_i)}), \quad k_i\in[\![0,k]\!]
\end{aligned}\]

<p>is updated through \(i_k\)-th term of the sum, where \(i_k\) is once again
an index randomly chosen at each iteration. The term
\(\nabla f_{i_k}(\theta^{(k_{i_k})})\) is replaced by
\(\nabla f_{i_k}(\theta^{(k)})\) in the sum, where
\((\theta^{(k)})_{k\ge 0}\) are obtained through a GD iteration step in
which the gradient is replaced by \(g^{(k)}\).</p>

<p><img src="/images/stoML/alg4.png" alt="" /></p>

<p>This algorithm has the same update cost as SGD but the averaged gradient
\(g^{(k)}\) has a smaller variance than the gradient used in SGD.
Moreover, choosing a constant step size \(\gamma_k=\frac{1}{2nL}\) yields
a convergence rate of \(\mathcal{O}((1- \frac{1}{8Ln})^k)\). However, it
is required to store at all time \(n\) elementary gradients
\(\nabla f_i(\theta^{(k_i)})\) as one of them is systematically used in
the updating step of \(g^{(k)}\).</p>

<h2 id="generalization-risk">Generalization risk</h2>

<p>Using the Empirical risk to determine the best predictor \(\theta^*\)
given the data arises several problems. First, to avoid over-fitting, a
regularisation function must be set. Then, the number of iterations
needed to achieve the optimum is hard to predict.</p>

<p>On the other hand, using Generalisation risk yields a more general
approach given that it measures how accurately we may predict outcome
values for previously unseen data (through the expectation). Therefore,
regularisation is no longer needed. As we may see now, SGD can be used
to minimise the generalisation risk, even though its expression is
unknown.</p>

<p>SGD would replace computations of the gradient of the Generalisation
risk \(\nabla\mathcal{R}(\theta^{(k-1)})\) by a proxy
\(g^{(k)}(\theta^{(k-1)})\) verifying :</p>

\[\begin{equation}
\mathbb{E}[g^{(k)}(\theta^{(k-1)})\vert \mathcal{F}_{k-1} ]=\nabla{\mathcal{R}}(\theta^{(k-1)})=\mathbb{E}_\rho[\nabla l(Y, \langle\theta^{(k-1)}, \Phi(X)\rangle)]
\tag{2}\label{SGD_origin_GR}
\end{equation}\]

<p>Considering that the examples
\((x_i,y_i)_{1\le i \le n}\) are i.i.d from \(\rho\), we can take for
\(g^{(k)}\) at iteration \(1\le k \le n\):</p>

\[\begin{aligned}
g^{(k)}(\theta^{(k-1)})=\nabla l(y_k, \langle\theta^{(k-1)}, \Phi(x_k)\rangle)
\end{aligned}\]

<p>and the filtrations
\(\mathcal{F}_{k-1}=\sigma((x_i,y_i)_{1\le i \le k})\). Therefore there is
a single pass through the data in this algorithm, and exactly \(n\)
iterations are needed. Hence, with a convex (resp. strongly convex) loss
function and a constant step size, it has a convergence rate of
\(\mathcal{O}(1/\sqrt{n})\) (resp. \(\mathcal{O}(1/(\mu n))\)).</p>

<p><img src="/images/stoML/alg5.png" alt="" /></p>

<h2 id="beyond-least-squares-for-generalisation-risk--sgd-as-a-markov-chain">Beyond Least squares for Generalisation risk : SGD as a Markov chain</h2>

<p>All the convergence rates previously mentioned are related to the use of
a quadratic loss function
\((x,y) \mapsto l(x,\theta(x))=(y-\theta^T\Phi(x))^2\). When using other
loss functions, the results don’t hold, and the SGD may even not
converge! For instance, for the logistic loss
\((x,y) \mapsto l(x,\theta(x))=\log\left(1+\exp(y-\theta^T\Phi(x))\right)\)
averaged SGD with constant step size \(\gamma\) happened to yield
convergence rates of
\(\mathbb{E}[\bar\theta^{(k)}-\theta^*]=\mathcal{O}(\gamma)\) (therefore
independent of the number of iterations...).</p>

<p>To understand this problem and come up with solutions, SGD (with
constant step size) was formulated as an homogeneous Markov chain.</p>

<p>Consider a \(L\)-smooth and \(\mu\)-strongly convex risk \(\mathcal{R}\). Then
SGD with a step size \(\gamma\) may be seen as the generation of a
sequence \((\theta^{(k)}_\gamma)_{k\ge 0}\) with recurrence :</p>

\[\begin{aligned}
\theta^{(k)}_\gamma=\theta^{(k-1)}_\gamma-\gamma\underbrace{\left(\nabla\mathcal{R}(\theta^{(k-1)}_\gamma)+\varepsilon^{(k)}(\theta^{(k-1)}_\gamma) \right)}_{=g^{(k)}(\theta^{(k-1)}_\gamma)}
\end{aligned}\]

<p>where \((\varepsilon^{(k)})_{k\ge 0}\) are i.i.d. random noises verifying
for any \(\theta\),
\(\mathbb{E}[\varepsilon^{(k)}(\theta)\vert \mathcal{F}_{k-1}]=0\) for the
same filtrations as in \eqref{SGD_origin_GR}. Introduced like this,
\((\theta^{(k)}_\gamma)_{k\ge 0}\) is a homogeneous Markov chain, which
allow us to understand the general behaviour of the SGD.</p>

<p>Indeed, this Markov chain will converge exponentially fast to its
(unique) stationary distribution \(\pi_\gamma\). Consequently, this
sequence (and therefore the SGD) does not converge to a point, but
rather will (asymptotically) oscillate around the mean
\(\bar\theta_\gamma = \mathbb{E}_{\pi_\gamma}[\theta]\) with an average
magnitude \(\gamma^{1/2}\). On the other hand, considering as an output
the average \(\bar\theta^{(k)}_\gamma\) of the \(k+1\) states
\(\lbrace\theta^{(i)} :0\le  i \le k \rbrace\), we can prove (central
limit theorem) that with rate \(\mathcal{O}(1/\sqrt{k})\) :</p>

\[\begin{aligned}
\bar\theta^{(k)}_\gamma \mathop{\rightarrow}\limits_{k\rightarrow \infty}^{L^2} \bar\theta_\gamma = \mathbb{E}_{\pi_\gamma}[\theta]
\end{aligned}\]

<p>Therefore the output of the averaged SGD is known to converge at a given
rate to \(\bar\theta_\gamma\), which may different than the optimum
\(\theta^*\). The error between the output of the SGD
\(\theta^{(k)}_\gamma\) and the optimum can be decomposed:</p>

\[\begin{aligned}\theta^{(k)}_\gamma-\theta^*=\underbrace{\theta^{(k)}_\gamma-\bar\theta_\gamma}_{\mathcal{O}(1/\sqrt{k})}+\underbrace{\bar\theta_\gamma - \theta^*}_{\text{independent of k}}
\end{aligned}\]

<p>Notice that if we take \(\theta^{(0)}_\gamma \sim \pi_\gamma\), then by
definition of \(\pi_\gamma\),</p>

\[\begin{aligned}
\theta^{(0)}_\gamma -\gamma\left(\nabla\mathcal{R}(\theta^{(0)}_\gamma)+\varepsilon^{(1)}(\theta^{(0)}_\gamma) \right)=\theta^{(1)}_\gamma  \sim \pi_\gamma
\end{aligned}\]

<p>Hence, by taking the expectation under \(\pi_\gamma\) we get :</p>

\[\begin{aligned}
\mathbb{E}_{\pi_\gamma}[\nabla\mathcal{R}(\theta^{(0)}_\gamma)]=0
\end{aligned}\]

<p>and recalling the expression of \(\mathcal{R}\) we get</p>

\[\begin{aligned}
\mathbb{E}_{\pi_\gamma}[\nabla\mathcal{R}(\theta)]=\mathbb{E}_{\pi_\gamma}\left[\mathbb{E}_\rho[\nabla l(Y, \Phi(X)^T\theta)]\right]=\mathbb{E}_\rho\left[\mathbb{E}_{\pi_\gamma}[\nabla l(Y, \Phi(X)^T\theta)]\right]=0
\end{aligned}\]

<p>In particular, in the quadratic loss case, given that
\(\theta \mapsto \nabla l(Y, \Phi(X)^T\theta)=2(Y-\Phi(X)^T\theta)\Phi(X)\)
is a linear function of \(\theta\), we have</p>

\[\begin{aligned}
\mathbb{E}_\rho\left[\mathbb{E}_{\pi_\gamma}[\nabla l(Y, \Phi(X)^T\theta)]\right]=\mathbb{E}_\rho\left[\nabla l(Y, \Phi(X)^T\mathbb{E}_{\pi_\gamma}[\theta])\right]=\nabla\mathcal{R}(\mathbb{E}_{\pi_\gamma}[\theta])=0
\end{aligned}\]

<p>And therefore,</p>

\[\begin{aligned}
\bar\theta_\gamma = \mathbb{E}_{\pi_\gamma}[\theta]=\theta^*.
\end{aligned}\]

<p>We retrieve the fact that in the quadratic loss case, the averaged SGD
converges to the optimum at rate \(\mathcal{O}(1/\sqrt{k})\).</p>

<p>However, in the general case, using a Taylor expansion of \(\mathcal{R}\),
we can only show that</p>

\[\begin{equation}
\bar\theta_\gamma = \theta^*+\gamma C +\mathcal{O}(\gamma^2)
\tag{3}\label{gen_output}
\end{equation}\]

<p>where \(C\) is a constant independent of \(\gamma\).
Therefore the averaged SGD will only converge to a point "near" the
optimum. To get a better estimate of \(\theta^*\), we can use Richardson
extrapolation. For instance, for two terms, the idea is to run SGD with
rates \(\gamma\) and \(2\gamma\), which will yield estimates of
\(\bar\theta_\gamma\) and \(\bar\theta_{2\gamma}\). Then, from
\eqref{gen_output}, notice that :</p>

\[\begin{aligned}
2\bar\theta_\gamma - \bar\theta_{2\gamma} = \theta^* + \mathcal{O}(\gamma^2)
\end{aligned}\]

<p>is a better estimate of \(\theta^*\). This approach can simply be
generalized to more terms (runs of the SGD).</p>

<figure>
  <img src="/images/stoML/sgd_general.png" />
  <figcaption>(Left) Convergence of iterates $\theta^{(k)}_\gamma$ and averaged
iterates $\bar\theta^{(k)}_\gamma$ to the mean $\bar\theta_\gamma$ under
the stationary distribution $\pi_\gamma$. (Right) Richardson-Romberg
extrapolation, the disks are of radius $\mathcal{O}(\gamma^2)$. Source :
(Dieuleveut, 2017).</figcaption>
</figure>

<h2 id="references">References</h2>

<ul>
  <li>
    <p>Bach, F. (2012). <em>Stochastic gradient methods for machine learning</em>.
Technical report. INRIA-ENS, Paris, France. Available at <a href="http://www.di.ens.fr/~fbach/fbach_sgd_online.pdf">http://www.di.ens.fr/~fbach/fbach_sgd_online.pdf</a></p>
  </li>
  <li>
    <p>Dieuleveut, A., Durmus, A., Bach, F. (2017). Bridging the Gap between
Constant Step Size Stochastic Gradient Descent and Markov Chains. arXiv
preprint arXiv:1707.06386.</p>
  </li>
  <li>
    <p>Dieuleveut, A. (2017, December). <em>Stochastic algorithms in Machine
Learning</em>. Paper presented at "Journée algorithmes stochastiques",
Université Paris Dauphine, Paris, France.</p>
  </li>
  <li>
    <p>Roux, N. L., Schmidt, M., Bach, F. R. (2012). <em>A stochastic gradient
method with an exponential convergence rate for finite training sets</em>.
In Advances in Neural Information Processing Systems (pp. 2663-2671).</p>
  </li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#feynmac-kac" class="page__taxonomy-item" rel="tag">Feynmac-Kac</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#particle-filtering" class="page__taxonomy-item" rel="tag">Particle filtering</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#sequential-monte-carlo" class="page__taxonomy-item" rel="tag">Sequential Monte Carlo</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/posts/2018/01/stoML/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/posts/2018/01/stoML/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/posts/2018/01/stoML/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/posts/2018/01/seqMC/" class="pagination--pager" title="Sequential Monte Carlo: Introduction and advances
">Previous</a>
    
    
      <a href="http://localhost:4000/posts/2019/10/pg2019/" class="pagination--pager" title="A few take-away messages from the conference Petroleum Geostatistics 2019
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      
        <h4 class="page__related-title">You May Also Enjoy</h4>
      
      <div class="grid__wrapper">
        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2019/10/pg2019/" rel="permalink">A few take-away messages from the conference Petroleum Geostatistics 2019
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  2 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2019-10-01T00:00:00-07:00">October 01, 2019</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>On September 2-6, 2019, I attended on behalf of <a href="https://estimages.com/">Estimages</a> (the company funding my PhD) the conference <a href="https://www.earthdoc.org/content/proceedings/florence2019">Petroleum Geostatistics 2019</a> in Florence, Italy. Here is my take on the messages that were delivered during this exciting conference.</p>

</p>
    
    
    

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2018/01/seqMC/" rel="permalink">Sequential Monte Carlo: Introduction and advances
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  5 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-01-18T00:00:00-08:00">January 18, 2018</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This note is an attempt to convey the main ideas and notions of the talk entitled “Sequential Monte Carlo: Introduction and advances” given by Nicolas Chopin (ENSAE, Paris, France) during the Stochastic algorithm Day 2017 (<em>Journée algorithmes stochastiques 2017</em>). This conference was held at Université Paris Dauphine (Paris, France) on December 1st, 2017.</p>

</p>
    
    
    

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2018/01/mcmc_tall/" rel="permalink">Markov chain Monte Carlo and tall data
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  9 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-01-18T00:00:00-08:00">January 18, 2018</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This note is an attempt to convey the main ideas and notions of the talk entitled “On Markov chain Monte Carlo and tall data” given by Rémi Bardenet (CNRS, Lille, France) during the Stochastic algorithm Day 2017 (<em>Journée algorithmes stochastiques 2017</em>). This conference was held at Université Paris Dauphine (Paris, France) on December 1st, 2017.</p>

</p>
    
    
    

  </article>
</div>

        
      </div>
    </div>
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/mike-pereira"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Mike Pereira. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

